{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deep-translator\n",
      "  Downloading deep_translator-1.8.3-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.23.0 in c:\\users\\vandarcia\\miniconda3\\envs\\gvenv\\lib\\site-packages (from deep-translator) (2.27.1)\n",
      "Collecting beautifulsoup4<5.0.0,>=4.9.1\n",
      "  Downloading beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
      "Collecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vandarcia\\miniconda3\\envs\\gvenv\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\vandarcia\\miniconda3\\envs\\gvenv\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vandarcia\\miniconda3\\envs\\gvenv\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\vandarcia\\miniconda3\\envs\\gvenv\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.0.12)\n",
      "Installing collected packages: soupsieve, beautifulsoup4, deep-translator\n",
      "Successfully installed beautifulsoup4-4.11.1 deep-translator-1.8.3 soupsieve-2.3.2.post1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install deep-translator \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import en_core_web_sm\n",
    "from deep_translator import GoogleTranslator \n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['api',\n",
       " 'rest',\n",
       " 'shell',\n",
       " 'cli',\n",
       " 'cronjobs',\n",
       " 'python',\n",
       " 'java',\n",
       " 'scala',\n",
       " 'go',\n",
       " 'sql']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JobSkills = pd.read_excel(r\"..\\NLP\\ResumeSkill_preprocessed.xlsx\")\n",
    "# lower characters and add spaces to the side to spot the complete words\n",
    "# DE_JobSkills = (\" \" + JobSkills[\"Data_Engineer\"].dropna().str.lower() + \" \").to_list()\n",
    "DE_JobSkills = JobSkills[\"Data_Engineer\"].dropna().str.lower().to_list()\n",
    "DE_JobSkills[0:10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_FILEPATH = r\"..\\Bumeran\\bumeran_scraped_data_22-06-2022_1129.json\"\n",
    "json_df = pd.read_json(JSON_FILEPATH, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyWords</th>\n",
       "      <th>title_role</th>\n",
       "      <th>description</th>\n",
       "      <th>date_published</th>\n",
       "      <th>schema</th>\n",
       "      <th>consulted_datetime</th>\n",
       "      <th>source</th>\n",
       "      <th>company_rate</th>\n",
       "      <th>salary</th>\n",
       "      <th>company</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ingeniero de datos, data engineer]</td>\n",
       "      <td>Analytics Data Engineer</td>\n",
       "      <td>Somos una empresa 100% mexicana con más de 25 ...</td>\n",
       "      <td>Publicado hace más de 30 días</td>\n",
       "      <td>Presencial</td>\n",
       "      <td>22/06/2022, 11:29</td>\n",
       "      <td>https://www.bumeran.com.mx/empleos/analytics-d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No especificado</td>\n",
       "      <td>Human Quality</td>\n",
       "      <td>Cuajimalpa de Morelos, Distrito Federal, Mexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ingeniero de datos, data engineer]</td>\n",
       "      <td>Data Engineer with Azure and Analytics</td>\n",
       "      <td>Somos una empresa 100% mexicana con más de 25 ...</td>\n",
       "      <td>Publicado hace más de 30 días</td>\n",
       "      <td>Presencial</td>\n",
       "      <td>22/06/2022, 11:29</td>\n",
       "      <td>https://www.bumeran.com.mx/empleos/data-engine...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No especificado</td>\n",
       "      <td>Human Quality</td>\n",
       "      <td>Cuajimalpa de Morelos, Distrito Federal, Mexico</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              keyWords  \\\n",
       "0  [ingeniero de datos, data engineer]   \n",
       "1  [ingeniero de datos, data engineer]   \n",
       "\n",
       "                               title_role  \\\n",
       "0                 Analytics Data Engineer   \n",
       "1  Data Engineer with Azure and Analytics   \n",
       "\n",
       "                                         description  \\\n",
       "0  Somos una empresa 100% mexicana con más de 25 ...   \n",
       "1  Somos una empresa 100% mexicana con más de 25 ...   \n",
       "\n",
       "                  date_published      schema consulted_datetime  \\\n",
       "0  Publicado hace más de 30 días  Presencial  22/06/2022, 11:29   \n",
       "1  Publicado hace más de 30 días  Presencial  22/06/2022, 11:29   \n",
       "\n",
       "                                              source  company_rate  \\\n",
       "0  https://www.bumeran.com.mx/empleos/analytics-d...           NaN   \n",
       "1  https://www.bumeran.com.mx/empleos/data-engine...           NaN   \n",
       "\n",
       "            salary        company  \\\n",
       "0  No especificado  Human Quality   \n",
       "1  No especificado  Human Quality   \n",
       "\n",
       "                                              city  \n",
       "0  Cuajimalpa de Morelos, Distrito Federal, Mexico  \n",
       "1  Cuajimalpa de Morelos, Distrito Federal, Mexico  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rows_containing_salary = json_df.loc[json_df[\"description\"].str.contains(\"Salario\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_df['blob_en'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vandarcia\\AppData\\Local\\Temp\\ipykernel_18356\\4095072707.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  json_df['blob_en'][0] = translated_news\n"
     ]
    }
   ],
   "source": [
    "text = json_df['description'][0] \n",
    "\n",
    "if len(text) >= 5000: \n",
    "\n",
    "    # sentences = text.split(sep = '.') \n",
    "\n",
    "    text = text.replace('\\n', ' ') \n",
    "\n",
    "    sentences = re.split(r'(?<=\\D)\\.(?=.)|(?<=\\d)\\.(?=\\D)', text) \n",
    "\n",
    "    # filter_object = filter(lambda x: x != \"\", sentences) \n",
    "\n",
    "    filter_object = filter(lambda x: len(x) > 2, sentences) \n",
    "\n",
    "    sentences = list(filter_object) \n",
    "\n",
    "    filter_object = filter(lambda x: bool(re.search('[a-zA-Z]', x)), sentences)  \n",
    "\n",
    "    sentences = list(filter_object) \n",
    "\n",
    "    filter_object = filter(lambda x: (sum(c.isalpha() for c in x)) > 2, sentences) \n",
    "\n",
    "    sentences = list(filter_object) \n",
    "\n",
    "    translated = GoogleTranslator('es', 'en').translate_batch(sentences) \n",
    "\n",
    "    translated_news = '. '.join(translated) \n",
    "\n",
    "    json_df['blob_en'][0] = translated_news \n",
    "\n",
    "else: \n",
    "\n",
    "    translated_news = GoogleTranslator(source='es', target='en').translate(text) \n",
    "\n",
    "    json_df['blob_en'][0] = translated_news "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"We are a 100% Mexican company with more than 25 years of experience in connecting talent with companies.\\n\\n\\nAnalytics Data Engineer in Monterrey, Guadalajara and AguasCalientes\\nThe ideal candidate is a motivated individual who is excited about making an impact to a user base of over 20k that is ready to operate in a fast-paced environment and can clearly demonstrate a thirst for learning and mastering emerging technologies, processes and tools in the analyticsspace. This person should take initiative and shouldn't be an order taker. They should enjoy optimizing data models to industry standards.\\n\\n\\nKey Requirements:\\n\\n1. Enterprise level SSAS / Tabular DAX Modeling experience\\n2. Experience with SQL Querying\\n3. Experienced with agile processes and methodologies\\n4. Experience with Production Models & troubleshooting skills\\n5. Ability to demonstrate understanding of business requirements & business concepts\\n\\nFollowing skills are not required but are a plus :\\n\\n6. Experience working with a team using Git\\n7. Spark/Databricks Experience\\n8. Experience with Build/Release Pipelines in Azure DevOps\\n\\nAdvanced English\\n\\n\\n Salary: $5200000 - $15000000 MXN\\n\\nFor now the position is remote but based on client's requirement, after Pandemic resource might required to be onsite to either one of these 3 locations. Guadalajara, Monterrey and .\\n\\nOur Ideal Candidate:\\n-Advanced English\\n\\nLocation: Cuajimalpa de Morelos, Federal District\\nDisability: This vacancy is suitable for people with disabilities.\\n\\n\\nThe selection process is carried out through AIRA - a recruitment platform designed to improve your application experience.\\n\\nTo apply you just need:\\n1. Apply for the offer\\n2. Check your mail\\n3. Enter AIRA and answer the questions and/or tests requested\\n\\nThen, if we see that your profile fits what we are looking for, we will contact you by mail (through AIRA) to continue to the face-to-face stage.\\nREF:15-8711-1648165198\""
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAMPLE_TEXT = json_df['blob_en'][0]\n",
    "SAMPLE_TEXT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'we are a 100  mexican company with more than 25 years of experience in connecting talent with companies    analytics data engineer in monterrey  guadalajara and aguascalientes the ideal candidate is a motivated individual who is excited about making an impact to a user base of over 20k that is ready to operate in a fast paced environment and can clearly demonstrate a thirst for learning and mastering emerging technologies  processes and tools in the analyticsspace  this person should take initiative and shouldn t be an order taker  they should enjoy optimizing data models to industry standards    key requirements   1  enterprise level ssas   tabular dax modeling experience 2  experience with sql querying 3  experienced with agile processes and methodologies 4  experience with production models   troubleshooting skills 5  ability to demonstrate understanding of business requirements   business concepts  following skills are not required but are a plus    6  experience working with a team using git 7  spark databricks experience 8  experience with build release pipelines in azure devops  advanced english    salary  $5200000   $15000000 mxn  for now the position is remote but based on client s requirement  after pandemic resource might required to be onsite to either one of these 3 locations  guadalajara  monterrey and    our ideal candidate   advanced english  location  cuajimalpa de morelos  federal district disability  this vacancy is suitable for people with disabilities    the selection process is carried out through aira   a recruitment platform designed to improve your application experience   to apply you just need  1  apply for the offer 2  check your mail 3  enter aira and answer the questions and or tests requested  then  if we see that your profile fits what we are looking for  we will contact you by mail  through aira  to continue to the face to face stage  ref 15 8711 1648165198'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Cleaning\n",
    "\n",
    "def clean_text_round1(text):\n",
    "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
    "    text = text.lower()\n",
    "    # text = re.sub('\\[.*?¿\\]\\%', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s$]', ' ', text) \n",
    "    # text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text)\n",
    "    # text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = re.sub('[‘’“”…«»]', '', text)\n",
    "    text = re.sub('\\n', ' ', text)\n",
    "    return text\n",
    " \n",
    " \n",
    "data_clean = clean_text_round1(SAMPLE_TEXT)\n",
    " \n",
    "\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'api': [],\n",
       " 'rest': [],\n",
       " 'shell': [],\n",
       " 'cli': [],\n",
       " 'cronjobs': [],\n",
       " 'python': [],\n",
       " 'java': [],\n",
       " 'scala': [],\n",
       " 'go': [],\n",
       " 'sql': [(700, 705)],\n",
       " 'acid': [],\n",
       " 'cap': [],\n",
       " 'oltp': [],\n",
       " 'olap': [],\n",
       " 'mysql': [],\n",
       " 'postgresql': [],\n",
       " 'mariadb': [],\n",
       " 'amazon aurora': [],\n",
       " 'mongodb': [],\n",
       " 'elasticsearch': [],\n",
       " 'apache couchdb': [],\n",
       " 'azure cosmosdb': [],\n",
       " 'apache cassandra': [],\n",
       " 'apache hbase': [],\n",
       " 'google bigtable': [],\n",
       " 'neo4j': [],\n",
       " 'amazon neptune': [],\n",
       " 'redis': [],\n",
       " 'memcached': [],\n",
       " 'amazon dynamodb': [],\n",
       " 'snowflake': [],\n",
       " 'presto': [],\n",
       " 'apache hive': [],\n",
       " 'apache impala': [],\n",
       " 'amazon redshift': [],\n",
       " 'azure synapse': [],\n",
       " 'clickhouse': [],\n",
       " 'apache hadoop': [],\n",
       " 'hdfs': [],\n",
       " 'mapreduce': [],\n",
       " 'amazon mr': [],\n",
       " 'google dataproc': [],\n",
       " 'azure data lake': [],\n",
       " 'apache pig': [],\n",
       " 'apache arrow': [],\n",
       " 'data build tool': [],\n",
       " 'apache spark': [],\n",
       " 'apache beam': [],\n",
       " 'apache flink': [],\n",
       " 'apache nifi': [],\n",
       " 'apache kafka': [],\n",
       " 'apache storm': [],\n",
       " 'apache samza': [],\n",
       " 'amazon kinesis': [],\n",
       " 'amazon sns and sqs': [],\n",
       " 'google pubsub': [],\n",
       " 'azure services bus': [],\n",
       " 'rabbitmq': [],\n",
       " 'apache airflow': [],\n",
       " 'google composer': [],\n",
       " 'apache oozie': [],\n",
       " 'luigi': [],\n",
       " 'prometheus': [],\n",
       " 'datadog': [],\n",
       " 'sentry': [],\n",
       " 'statsd': [],\n",
       " 'http/https': [],\n",
       " 'ssh': [],\n",
       " 'tcp': [],\n",
       " 'ip': [],\n",
       " 'dns': [],\n",
       " 'docker': [],\n",
       " 'lxc': [],\n",
       " 'kubernetes': [],\n",
       " 'docker swarm': [],\n",
       " 'apache mesos': [],\n",
       " 'gke': [],\n",
       " 'terraform': [],\n",
       " 'pulumi': [],\n",
       " 'aws cdk': [],\n",
       " 'github actions': [],\n",
       " 'jenkins': [],\n",
       " 'active directory': [],\n",
       " 'azure active directory': [],\n",
       " 'ssas': [(642, 648)],\n",
       " 'ssis': [],\n",
       " 'data factory': [],\n",
       " 'sql server': []}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# { jobSkill:[x.span() for x in re.finditer(jobSkill,SAMPLE_TEXT.lower())]  for jobSkill in DE_JobSkills} \n",
    "JobSkillsLoc = { jobSkill:[x.span() for x in re.finditer(\" \"+ jobSkill + \" \",data_clean)] for jobSkill in DE_JobSkills} \n",
    "JobSkillsLoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load(\"es_core_news_sm\")\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "\n",
    "# skill = \"XPATH\" \n",
    "# [skill[:],\"Skill\"]\n",
    "\n",
    "\n",
    "# {\"SKILL\",\"\"}\n",
    "# Vales de despensa, \"Beneficios\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(rows_containing_salary[\"description\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% PERCENT\n",
      "de experiencia PERSON\n",
      "con ORG\n",
      "Analytics Data Engineer ORG\n",
      "Monterrey GPE\n",
      "Guadalajara GPE\n",
      "20k DATE\n",
      "SSAS / ORG\n",
      "2 CARDINAL\n",
      "SQL Querying ORG\n",
      "3 CARDINAL\n",
      "4 CARDINAL\n",
      "Production Models ORG\n",
      "5 CARDINAL\n",
      "Git ORG\n",
      "7 CARDINAL\n",
      "Spark/Databricks Experience ORG\n",
      "8 CARDINAL\n",
      "English LANGUAGE\n",
      "MXN  \n",
      "\n",
      " ORG\n",
      "one CARDINAL\n",
      "3 CARDINAL\n",
      "Guadalajara GPE\n",
      "Monterrey PERSON\n",
      "English LANGUAGE\n",
      "Cuajimalpa de Morelos PERSON\n",
      "Distrito Federal ORG\n",
      "apta para personas PERSON\n",
      "El proceso de selección ORG\n",
      "diseñado para PERSON\n",
      "tu experiencia de PERSON\n",
      "1 CARDINAL\n",
      "2 CARDINAL\n",
      "Revisar tu mail PERSON\n",
      "3 CARDINAL\n",
      "vemos que PERSON\n",
      "tu perfil PERSON\n",
      "estamos NORP\n",
      "la GPE\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text,ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a6c709b79dbce7a5e8d32b3dbd4ee5af952751da183d01f4f9c87648309826e0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('gvenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
